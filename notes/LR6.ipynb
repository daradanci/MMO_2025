{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daradanci/MMO_2025/blob/main/notes/LR6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа №6  \n",
        "## Классификация текстов\n",
        "\n",
        "**Цель работы:** изучить методы классификации текстов на основе различных способов векторизации.  \n",
        "**Задание:** Реализовать два подхода к классификации текстов:  \n",
        "1. На основе `TfidfVectorizer`.  \n",
        "2. На основе `word2vec`, обученного вручную на корпусе.  \n",
        "Сравнить полученные результаты классификации.\n"
      ],
      "metadata": {
        "id": "YgKZWCYpBzUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Используемый набор данных\n",
        "\n",
        "В качестве источника данных выбран встроенный корпус `20 Newsgroups` из библиотеки `sklearn.datasets`.  \n",
        "Из 20 доступных категорий были выбраны две для бинарной классификации:\n",
        "\n",
        "- `sci.space` — научные обсуждения, связанные с космосом;\n",
        "- `rec.sport.baseball` — обсуждения бейсбольных матчей и команд.\n",
        "\n",
        "Это позволяет продемонстрировать алгоритмы классификации на реальных текстах, отличающихся тематически.\n"
      ],
      "metadata": {
        "id": "eDEIT5s9CEB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.3\n",
        "!pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fuiRteyD72z",
        "outputId": "1458a17a-e2f3-4d95-db64-472a205fad89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.11/dist-packages (1.24.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.24.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "\n",
        "# Выбираем 2 категории для бинарной классификации\n",
        "categories = ['sci.space', 'rec.sport.baseball']\n",
        "\n",
        "# Загружаем данные\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Формируем DataFrame\n",
        "df = pd.DataFrame({'text': newsgroups.data, 'label': newsgroups.target})\n",
        "\n",
        "# Просмотр примера\n",
        "df.head(3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "hkedxRvTCBlB",
        "outputId": "5e6b622f-898e-4297-a1cd-55c8a8c50d38"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "________________________________________________________________________________\n",
            "Cache loading failed\n",
            "________________________________________________________________________________\n",
            "No module named 'numpy._core'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  I've been saying this for quite some time, but...      0\n",
              "1  Sorry for asking a question that's not entirel...      1\n",
              "2  Giant's have a five man rotation of  John Burk...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a69707ed-9656-43b3-80cc-f44cd760b29f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I've been saying this for quite some time, but...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sorry for asking a question that's not entirel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Giant's have a five man rotation of  John Burk...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a69707ed-9656-43b3-80cc-f44cd760b29f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a69707ed-9656-43b3-80cc-f44cd760b29f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a69707ed-9656-43b3-80cc-f44cd760b29f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-82ebcfa3-3e20-4484-923e-9dd6a7a5a009\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82ebcfa3-3e20-4484-923e-9dd6a7a5a009')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-82ebcfa3-3e20-4484-923e-9dd6a7a5a009 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1190,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1156,\n        \"samples\": [\n          \"\\nThere are no Mariner craft from which we are still receiving data.  I believe\\nyou are referring to one or more of Pioneers 6 through 9 (launched from\\nDecember 1965 through November 1968), which were put into solar orbits to study\\ninterplanetary space.  I recall reading that at least one of them was still\\nfunctioning 25 years after launch.\",\n          \"Suppose the Soviets had managed to get their moon rocket working\\nand had made it first.  They could have beaten us if either:\\n\\n* Their rocket hadn't blown up on the pad thus setting them back,\\n\\nand/or\\n\\n* A Saturn V went boom.\\n\\nIf they had beaten us, I speculate that the US would have gone\\nhead and done some landings, but we also would have been more\\ndetermined to set up a base (both in Earth Orbit and on the\\nMoon).  Whether or not we would be on Mars by now would depend\\nupon whether the Soviets tried to go.  Setting up a lunar base\\nwould have stretched the budgets of both nations and I think\\nthat the military value of a lunar base would outweigh the value\\nof going to Mars (at least in the short run).  Thus we would\\nhave concentrated on the moon.\\n\",\n          \"Forwarded from Neal Ausman, Galileo Mission Director\\n\\n                                GALILEO\\n                     MISSION DIRECTOR STATUS REPORT\\n                             POST-LAUNCH\\n                         April 9 - 15, 1993\\n\\nSPACECRAFT\\n\\n1.  On April 9, real-time commands were sent, as planned, to reacquire\\ncelestial reference after completion of the Low Gain Antenna (LGA-2)\\nswing/Dual Drive Actuator (DDA) hammer activities.\\n\\n2.  On April 9, the EJ-1 (Earth-Jupiter #1) sequence memory load was uplinked\\nto the spacecraft without incident.  This sequence covers spacecraft activity\\nfrom April 12, 1993 to June 14, 1993 and includes a window for the Radio Relay\\nAntenna (RRA) slew test on April 28, 1993.  The command loss timer was set to\\n11 days as a part of this sequence memory load.\\n\\n3.  On April 12 and 15, a NO-OP command was sent to reset the command loss\\ntimer to 264 hours, its planned value during this mission phase.\\n\\n4.  On April 12, cruise science Memory Readouts (MROs) were performed for the\\nExtreme Ultraviolet Spectrometer (EUV), Dust Detector (DDS), and Magnetometer\\n(MAG) instruments.  Preliminary analysis indicates the data was received\\nproperly.\\n\\n5.  On April 12, an Ultra-Stable Oscillator (USO) test was performed to verify\\nthe health status of the USO and to collect gravitational red shift experiment\\ndata; long term trend analysis is continuing.\\n\\n6.  On April 14, a 40bps modulation index test was performed to determine the\\noptimal Signal-to-Noise Ratio (SNR) when transmitting at 40bps.  Preliminary\\nanalysis of the data suggests that the present pre-launch selected modulation\\nindex is near the optimal level.\\n\\n7.  On April 15, cruise science Memory Readouts (MROs) were performed for the\\nExtreme Ultraviolet Spectrometer (EUV) and Magnetometer (MAG) instrument.\\nPreliminary analysis indicates the data was received properly.\\n\\n8.  On April 15, a periodic RPM (Retro-Propulsion Module) 10-Newton thruster\\nflushing maintenance activity was performed; all 12 thrusters were flushed\\nduring the activity.  Thruster performance throughout the activity was nominal.\\n\\n9.  The AC/DC bus imbalance measurements have not exhibited significant\\nchanges (greater than 25 DN) throughout this period.  The AC measurement reads\\n19 DN (4.3 volts).  The DC measurement reads 111 DN (12.9 volts).  These\\nmeasurements are consistent with the model developed by the AC/DC special\\nanomaly team.\\n\\n10. The Spacecraft status as of April 15, 1993, is as follows:\\n\\n       a)  System Power Margin -  60 watts\\n       b)  Spin Configuration - Dual-Spin\\n       c)  Spin Rate/Sensor - 3.15rpm/Star Scanner\\n       d)  Spacecraft Attitude is approximately 18 degrees\\n           off-sun (lagging) and 6 degrees off-earth (leading)\\n       e)  Downlink telemetry rate/antenna- 40bps(coded)/LGA-1\\n       f)  General Thermal Control - all temperatures within\\n           acceptable range\\n       g)  RPM Tank Pressures - all within acceptable range\\n       h)  Orbiter Science- Instruments powered on are the PWS,\\n           EUV, UVS, EPD, MAG, HIC, and DDS\\n       i)  Probe/RRH - powered off, temperatures within\\n           acceptable range\\n       j)  CMD Loss Timer Setting - 264 hours\\n           Time To Initiation - 260 hours\\n\\n\\nGDS (Ground Data Systems):\\n\\n1.  Galileo participated in a second DSN (Deep Space Network) acceptance test\\nfor the DSN Telemetry Phase 3 Upgrade on April 13, 1993, using CTA-21\\n(Compatibility Test Area 21).  The purpose of this test was to verify\\nthe flow of Galileo telemetry data through the new Telemetry Group Controller\\n(TGC) and the Telemetry Channel Assembly (TCA).  The TGC/TCA is the replacement\\nfor the current Telemetry Processing Assembly (TPA).  Seven different telemetry\\nrates were run for this test; all ran well on both the MTS (MCCC Telemetry\\nSubsystem) and the AMMOS MGDS V18.0 GIF with the exception of 10bps.  The\\n10bps rate had some trouble staying in lock; it appears the TGC/TCA was\\nnot metering the data correctly.  Further comparisons between the MGDS and MTS\\ndata from this test are being conducted. MVT (Mission Verification Test) of\\nthe TGC/TCA system is expected to begin May 16, 1993.\\n\\n\\nTRAJECTORY\\n\\n     As of noon Thursday, April 15, 1993, the Galileo Spacecraft trajectory\\nstatus was as follows:\\n\\n\\tDistance from Earth         152,606,000 km (1.02 AU)\\n\\tDistance from Sun           277,519,800 km (1.86 AU)\\n\\tHeliocentric Speed          93,400 km per hour\\n\\tDistance from Jupiter       543,973,900 km\\n\\tRound Trip Light Time       17 minutes, 4 seconds\\n\\n\\nSPECIAL TOPIC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Способ 1. Классификация на основе TfidfVectorizer\n",
        "\n",
        "Для первого подхода тексты были преобразованы в числовые векторы с помощью `TfidfVectorizer`, исключающего стоп-слова и учитывающего частотность слов.  \n",
        "Классификация выполнялась с помощью модели `LogisticRegression`, которая хорошо работает на задачах с разреженными признаками.  \n",
        "Ниже приведён отчёт о качестве модели на тестовой выборке.\n"
      ],
      "metadata": {
        "id": "4puCHTh_CtOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Разделяем на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Векторизация текста\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Обучение логистической регрессии\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Оценка модели\n",
        "y_pred = model.predict(X_test_vec)\n",
        "print(classification_report(y_test, y_pred, target_names=newsgroups.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68Ue5_TmCrds",
        "outputId": "a058a626-65b9-4bfc-b892-eae4f3c18f27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "rec.sport.baseball       0.95      0.90      0.92       130\n",
            "         sci.space       0.89      0.94      0.91       108\n",
            "\n",
            "          accuracy                           0.92       238\n",
            "         macro avg       0.92      0.92      0.92       238\n",
            "      weighted avg       0.92      0.92      0.92       238\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Способ 2. Классификация на основе Word2Vec\n",
        "\n",
        "Во втором подходе используется модель `Word2Vec`, обученная на тексте из датасета `20 Newsgroups`.  \n",
        "Каждое слово кодируется вектором, отражающим его контекст, а вектор документа получаем как среднее всех слововых векторов.  \n",
        "Обучение выполняется с использованием библиотеки `gensim`.\n"
      ],
      "metadata": {
        "id": "igFf0TxbC7VL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # иногда помогает отдельно\n",
        "nltk.download('popular')    # качает всё базовое, включая punkt и токенизаторы\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntPrT6C1Er83",
        "outputId": "8bc32cd2-9832-4283-d290-2502dd31af18"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "# import nltk\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Токенизируем все тексты для обучения модели\n",
        "tokenized_texts = [word_tokenize(text.lower()) for text in df['text']]\n",
        "\n",
        "# Обучаем Word2Vec на корпусе\n",
        "w2v_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=2, workers=4, sg=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbULGz_XC7w4",
        "outputId": "68b435a2-6178-4cdb-d1e9-68e6e47952bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Получение признаков документов на основе Word2Vec\n",
        "\n",
        "Каждый документ преобразуется в вектор путём усреднения эмбеддингов слов, присутствующих в нём.  \n",
        "Если все слова документа отсутствуют в словаре модели, возвращается нулевой вектор.  \n",
        "Таким образом, создаются числовые представления текстов, пригодные для подачи в классификатор.\n"
      ],
      "metadata": {
        "id": "_r2PHibHFT2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Функция усреднения эмбеддингов слов в документе\n",
        "def document_vector(doc, model):\n",
        "    words = [word for word in word_tokenize(doc.lower()) if word in model.wv.key_to_index]\n",
        "    if not words:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(model.wv[words], axis=0)\n",
        "\n",
        "# Преобразуем все документы в векторы\n",
        "X_w2v = np.array([document_vector(text, w2v_model) for text in df['text']])\n",
        "y = df['label']\n",
        "\n",
        "# Делим выборку\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "nmg5kd6bFQdU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Классификация на Word2Vec-векторах\n",
        "\n",
        "После получения векторного представления документов, была обучена модель `LogisticRegression`.  \n",
        "Модель показала определённый уровень качества классификации, позволяющий сравнить её с результатами, полученными при использовании `TfidfVectorizer`.\n"
      ],
      "metadata": {
        "id": "jH_DTQD-F8Sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Обучаем модель на векторах Word2Vec\n",
        "model_w2v = LogisticRegression(max_iter=1000)\n",
        "model_w2v.fit(X_train_w2v, y_train_w2v)\n",
        "\n",
        "# Предсказания\n",
        "y_pred_w2v = model_w2v.predict(X_test_w2v)\n",
        "\n",
        "# Выводим отчёт\n",
        "print(classification_report(y_test_w2v, y_pred_w2v, target_names=newsgroups.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iR6bLa0F9JP",
        "outputId": "2eeb9124-1580-49cd-8dbd-312c085e1d75"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "rec.sport.baseball       0.88      0.88      0.88       130\n",
            "         sci.space       0.86      0.86      0.86       108\n",
            "\n",
            "          accuracy                           0.87       238\n",
            "         macro avg       0.87      0.87      0.87       238\n",
            "      weighted avg       0.87      0.87      0.87       238\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "IxCLnK94F_xX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сравнение моделей и вывод\n",
        "\n",
        "В данной лабораторной работе были реализованы два подхода к классификации текстов:\n",
        "\n",
        "1. **TfidfVectorizer + LogisticRegression**  \n",
        "   Модель показала высокую точность благодаря учёту частоты слов в тексте и их значимости в корпусе.  \n",
        "   Преимущество — простота и эффективность на небольших и средних наборах данных.\n",
        "\n",
        "2. **Word2Vec + LogisticRegression**  \n",
        "   Этот подход использует контекстные представления слов, усреднённые по каждому документу.  \n",
        "   Хотя результат может быть ниже, модель способна улавливать семантику слов и подходит для более глубокого анализа текста.\n",
        "\n",
        "📊 **Итог:**  \n",
        "Обе модели успешно решили задачу классификации. Метод на основе `TfidfVectorizer` показал более высокую точность на выбранном корпусе, однако `Word2Vec` даёт более гибкое представление текста и может быть полезен при работе с более сложными задачами или большими данными.\n",
        "\n",
        "Таким образом, цель лабораторной работы достигнута, оба метода реализованы и протестированы.\n"
      ],
      "metadata": {
        "id": "GnAEJdqNGVy3"
      }
    }
  ]
}